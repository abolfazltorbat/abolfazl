# -*- coding: utf-8 -*-
"""IAAA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S-DvwxLcnnpQxh2m89ozoBbdYrrFMIBx
"""

# Install gdown if not already installed
!pip install gdown

## ---------- download the dataset from the google drive


import gdown
import zipfile

# Public Google Drive link
url = 'https://drive.google.com/uc?id=1Z67yKzNNqaXfa0UglcodL5Q3L0pMN-dt'

# Specify the output file name
output = 'iaaa-mri-train.zip'

# Download the file
gdown.download(url, output, quiet=False)

# Extract the zip file
with zipfile.ZipFile(output, 'r') as zip_ref:
    zip_ref.extractall('iaaa_mri_train')

# Check the contents of the extracted folder
!ls iaaa_mri_train

!pip install pydicom

import os
import pandas as pd
import pydicom
import numpy as np
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, classification_report, precision_recall_curve
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler
from torchvision import transforms
from tqdm import tqdm
import seaborn as sns

# Load the CSV file and extract relevant columns
def load_labels(csv_path):
    labels_df = pd.read_csv(csv_path)[['SeriesInstanceUID', 'prediction']]
    print("CSV labels loaded.")
    return labels_df

# Load DICOM files from a given folder and return pixel arrays
def load_dicom_images(folder_path, num_images=16, target_size=(256, 256)):
    dicom_files = [f for f in os.listdir(folder_path) if f.endswith('.dcm')]
    images = []
    for dicom_file in dicom_files[:num_images]:
        dicom_path = os.path.join(folder_path, dicom_file)
        dicom_data = pydicom.dcmread(dicom_path)
        image = dicom_data.pixel_array

        # Resize the image to ensure consistency in shape
        image_resized = cv2.resize(image, target_size)
        images.append(image_resized)
    return np.array(images)

# Preprocess data by loading images and mapping them to the labels
def prepare_data(data_dir, labels_df):
    inputs, targets = [], []

    for idx, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc="Processing folders"):
        series_uid = row['SeriesInstanceUID']
        label = row['prediction']
        folder_path = os.path.join(data_dir, series_uid)

        if os.path.exists(folder_path):
            dicom_images = load_dicom_images(folder_path)
            inputs.append(dicom_images)
            targets.append(label)

            if idx ==100:
              break

    print("Data preparation completed.")
    return inputs, targets

# Statistical Visualization of the Class Distribution
def plot_class_distribution(targets):
    sns.countplot(x=targets)
    plt.title('Class Distribution')
    plt.show()

# Plot some images from each class
def plot_images_by_class(inputs, targets, num_samples=5):
    class_0 = [inputs[i][0] for i in range(len(targets)) if targets[i] == 0][:num_samples]
    class_1 = [inputs[i][0] for i in range(len(targets)) if targets[i] == 1][:num_samples]

    fig, axs = plt.subplots(2, num_samples, figsize=(15, 5))
    for i in range(num_samples):
        axs[0, i].imshow(class_0[i], cmap='gray')
        axs[0, i].set_title('Class 0')
        axs[1, i].imshow(class_1[i], cmap='gray')
        axs[1, i].set_title('Class 1')
    plt.show()


# Define paths to CSV and DICOM data folder
csv_path = '/content/iaaa_mri_train/train.csv'
data_dir = '/content/iaaa_mri_train/data/'

# Load and prepare the data
labels_df = load_labels(csv_path)
inputs, targets = prepare_data(data_dir, labels_df)

# Visualize class distribution
plot_class_distribution(targets)

# Plot some images from each class
plot_images_by_class(inputs, targets, num_samples=7)

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2, random_state=42, stratify=targets)

#!pip install gputil
import os
import torch
import torchvision.models.video as video_models
import numpy as np
import platform
import psutil
import matplotlib.pyplot as plt
from tqdm import tqdm
from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, ConcatDataset
from torchvision import transforms
from sklearn.model_selection import train_test_split
import torch.nn as nn
import torch.optim as optim
from datetime import datetime
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score




# Augmentation function with MRI-specific augmentations
def augmentations():
    return transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomRotation(degrees=10),
        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.9, 1.1)),
        transforms.ColorJitter(brightness=0.1, contrast=0.1),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5]),  # Normalize between -1 and 1
    ])

class MRIDataset(Dataset):
    def __init__(self, inputs, targets, transform=None, is_3d=False):
        """
        inputs: 3D MRI images
        targets: Labels for each image
        transform: Optional transformations
        is_3d: Flag to indicate whether the dataset is 3D or 2D
        """
        self.inputs = inputs
        self.targets = targets
        self.transform = transform
        self.is_3d = is_3d

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self, idx):
        if self.is_3d:
            # Handle 3D data (e.g., a volume of images)
            image = self.inputs[idx]  # Assuming the input is a 3D array [depth, height, width]
            image = np.expand_dims(image, axis=0)  # Add channel dimension [1, depth, height, width]
        else:
            # Handle 2D data by selecting the middle slice
            middle_slice_index = len(self.inputs[idx]) // 2
            image = self.inputs[idx][middle_slice_index]
            image = np.expand_dims(image, axis=2)  # Ensure single-channel

        # Convert from uint16 to float32 if needed (normalization)
        if image.dtype == np.uint16:
            image = image.astype(np.float32) / 65535.0  # Normalize between 0 and 1

        # If using 3D model, normalize across 3D volumes
        if self.is_3d:
            image = torch.tensor(image, dtype=torch.float32)  # Convert to torch tensor

        # If there are transformations (augmentations), apply them
        if self.transform and not self.is_3d:
            image = self.transform(image)

        label = self.targets[idx]  # Get the corresponding label

        return image, label

# 3D CNN model
class Pretrained3DCNN(nn.Module):
    def __init__(self, pretrained=True):

        super(Pretrained3DCNN, self).__init__()
        self.model = video_models.r3d_18(pretrained=pretrained)

        # Modify the first conv layer to accept a single channel input instead of 3
        self.model.stem[0] = nn.Conv3d(1, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)

        # Adjust the final fully connected layer for binary classification (2 classes)
        self.model.fc = nn.Linear(self.model.fc.in_features, 2)

    def forward(self, x):
        # Forward pass through the model
        return self.model(x)


# Improved 2D CNN Model
class ImprovedCNN(nn.Module):
    def __init__(self):
        super(ImprovedCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(256 * 32 * 32, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 2)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(self.relu(self.bn1(self.conv1(x))))
        x = self.pool(self.relu(self.bn2(self.conv2(x))))
        x = self.pool(self.relu(self.bn3(self.conv3(x))))
        x = x.view(-1, 256 * 32 * 32)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Handling class imbalance using WeightedRandomSampler
def get_sampler(targets):
    class_sample_counts = np.bincount(targets)
    weights = 1. / class_sample_counts
    sample_weights = weights[targets]
    return WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)

# Function to calculate class weights
def calculate_class_weights(targets):
    class_sample_counts = np.bincount(targets)
    class_weights = 1. / class_sample_counts
    class_weights = torch.FloatTensor(class_weights).to(device)
    return class_weights

# Function to calculate metrics
def calculate_metrics(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    return accuracy, precision, recall, f1

# Training function with early stopping and loss tracking
def train_model_with_early_stopping(model, train_loader, test_loader, criterion, optimizer, scheduler, device, num_epochs=20, patience=5):
    best_val_loss = float('inf')
    patience_counter = 0
    train_loss_history = []
    val_loss_history = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        train_loss = running_loss / len(train_loader)
        train_loss_history.append(train_loss)

        val_loss = validate_model(model, test_loader, criterion, device)
        val_loss_history.append(val_loss)

        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')

        scheduler.step()  # Adjust learning rate

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), 'best_model.pth')
            print(f"Saved best model at epoch {epoch+1}")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"Early stopping at epoch {epoch+1}")
                break

    plot_training_process(train_loss_history, val_loss_history)

    return model

# Validation function
def validate_model(model, test_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    y_true = []
    y_pred = []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, preds = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    val_loss = running_loss / len(test_loader)
    accuracy, precision, recall, f1 = calculate_metrics(y_true, y_pred)

    print(f'Validation Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')

    return val_loss

# Plot training and validation loss
def plot_training_process(train_loss, val_loss):
    plt.plot(train_loss, label='Train Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.title('Training and Validation Loss Over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()




# Main code for training the model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

use_3d_model = True  # Set to False if you want to use the 2D CNN

# Prepare the dataset and model
if use_3d_model:
    dataset = MRIDataset(X_train, y_train, transform=transforms.ToTensor(), is_3d=True)  # 3D data
    model = Pretrained3DCNN(pretrained=True).to(device)  # Load pretrained 3D CNN
else:
    dataset = MRIDataset(X_train, y_train, transform=transforms.ToTensor(), is_3d=False)  # 2D data
    model = ImprovedCNN().to(device)  # Load 2D CNN

# Set up data loaders, loss function, optimizer, and learning rate scheduler
train_loader = DataLoader(dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(MRIDataset(X_test, y_test, transform=transforms.ToTensor(), is_3d=use_3d_model), batch_size=16, shuffle=False)

class_weights = calculate_class_weights(y_train)  # Handle class imbalance
criterion = nn.CrossEntropyLoss(weight=class_weights)
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

# Train the model with early stopping
trained_model = train_model_with_early_stopping(
    model=model,
    train_loader=train_loader,
    test_loader=test_loader,
    criterion=criterion,
    optimizer=optimizer,
    scheduler=scheduler,
    device=device,
    num_epochs=1,
    patience=5
)

from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay, roc_curve,
                             roc_auc_score, classification_report, precision_recall_curve,
                             f1_score, jaccard_score)

# Function to load the saved model
def load_model(model_path, model_class, device):
    model = model_class().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    print(f"Model loaded from {model_path}")
    return model

# Evaluation function
def evaluate_model(model, test_loader, device):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    return np.concatenate(all_preds), np.concatenate(all_labels)

# Advanced evaluation with metrics and optional saving
def evaluate_metrics(y_true, y_pred, save_results=False):
    # Classification Report
    report = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'], output_dict=True)
    print("Classification Report:")
    print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1']))

    # Additional MRI metrics (Dice score and Jaccard index)
    dice_score = f1_score(y_true, y_pred, average='macro')  # Dice coefficient
    jaccard_index = jaccard_score(y_true, y_pred, average='macro')  # Jaccard Index
    print(f"Dice Score (F1-Score): {dice_score:.4f}")
    print(f"Jaccard Index: {jaccard_index:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])
    disp.plot(cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')

    if save_results:
        plt.savefig('results/confusion_matrix.png')
    plt.show()

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    auc = roc_auc_score(y_true, y_pred)
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.2f})')
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
    plt.title('ROC Curve')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")

    if save_results:
        plt.savefig('results/roc_curve.png')
    plt.show()

    # Precision-Recall Curve
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    plt.plot(recall, precision, color='green', label='Precision-Recall Curve')
    plt.title('Precision-Recall Curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.legend(loc="lower right")

    if save_results:
        plt.savefig('results/precision_recall_curve.png')
    plt.show()

    # Optionally save metrics as text or JSON
    if save_results:
        os.makedirs('results', exist_ok=True)
        with open('results/classification_report.txt', 'w') as f:
            f.write(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1']))
        with open('results/metrics_summary.txt', 'w') as f:
            f.write(f"Dice Score (F1-Score): {dice_score:.4f}\n")
            f.write(f"Jaccard Index: {jaccard_index:.4f}\n")
            f.write(f"ROC AUC: {auc:.4f}\n")

# Main evaluation process
def run_evaluation(model_class, model, test_loader, device, save_results=False):

    # Evaluate the model
    y_pred, y_true = evaluate_model(model, test_loader, device)

    # Advanced evaluation with metrics and visualizations, with optional saving
    evaluate_metrics(y_true, y_pred, save_results=save_results)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Define settings
save_results = True  # Set to True to save results and plots

# Run evaluation
run_evaluation(ImprovedCNN, model, test_loader, device, save_results=save_results)